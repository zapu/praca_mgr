\chapter{Conclusions}

The goal of this thesis was to research feasibility of building distributed computing system based on volunteer computing. Such system could be used to create Internet computing markets and potentially reduce needs to employ commercial computing grids, while encouraging both commercial and academic institutions to use distributed computing - because of lowering the costs of using the method. Part of lowering the costs could be the ability to use currently owned hardware and connect it to the system as computing nodes, therefore getting some of the spent money back.

Simulations were performed to see dynamics of volunteer computing system and research algorithms needed to efficiently compute work in a distributed way. Simulations have shown that proposed models can be used to provide a way of collecting and verifying results in a volunteer computing system or a computing cluster. However, defense from coordinated attacks using lots of colluding malicious nodes turned to outside of the scope of this thesis, because it is a huge challenge on its own. Special protections would have to be designed and employed just to protect from such attacks.

Simulations presented show a significant improvement over our previous simulator~\cite{zochniakreliable}. Firstly, we were able to simulate networks as big as $500$ nodes and $10,000$ jobs (previously: $50$ nodes and $1,000$ jobs). Secondly, changes in the job distribution model, and the trust model, caused the average number of confirmations to become lower in networks with malicious nodes. Also, the stabilization phase of computing project has been mostly eliminated.

A prototype was created, to investigate technical difficulties of building such system. Prototype proved that use of BitTorrent is feasible way of distributing projects, and that VirtualBox can be used as virtualization technology in order to provide flexibility of defining computing projects. 

\section*{Possible improvements}

The biggest downside of using the proposed model is inability to protect from large-scale coordinated malicious activities. In order to defuse such attack, the trust model of computing network would have to be very complicated. Heuristic methods should be employed instead. Measuring the way an honest node and a dishonest node completes jobs and use statistical methods to prevent abuse by determining which nodes may be cheating and which nodes are colluding with one another.

Another room for improvement exists in the area of simulator. In order to simulate big networks, some sort of parallel simulator has to be developed. Because our algorithms have global state (trust of one node is based on trust of all other nodes), parallelizing simulations is a nontrivial task.